[Coursera] Data Analysis: Assignment #2 - Exploratory
================================================================================

### Prompt

> Your task is to build a function that predicts what activity a subject is
> performing based on the quantitative measurements from the Samsung phone. For
> this analysis your training set must include the data from subjects 1, 3, 5,
> and 6.  But you may use more subjects data to train if you wish. Your test set
> is the data from subjects 27, 28, 29, and 30, but you may use more data to
> test. Be careful that your training/test sets do not overlap.
>
> You should perform all of the steps in building a predictive model and
> describe your analysis in a report as explained below. 

Source: <https://class.coursera.org/dataanalysis-001/human_grading/view/courses/294/assessments/5/submissions>

### Set the Stage

```{r}
setwd('~/Desktop/coursera-data-analysis/assignments/2/')
load('data/raw/samsungData.rda')

# literally hundreds of variables:
#names(samsungData)

unique(samsungData$subject)
# 1..30 --> minus: 2, 4, 9, 10, 12, 13, 18, 20, 24

### clean it up: ###
# `activity` as factor
samsungData$activity <- as.factor(samsungData$activity)

# clean the duplicate column names
for (n in 303:316) {
  colnames(samsungData)[n] <- paste("X-", colnames(samsungData)[n], sep="")
}
for (n in 317:330) {
  colnames(samsungData)[n] <- paste("Y-", colnames(samsungData)[n], sep="")
}
for (n in 331:344) {
  colnames(samsungData)[n] <- paste("Z-", colnames(samsungData)[n], sep="")
}
for (n in 382:395) {
  colnames(samsungData)[n] <- paste("X-", colnames(samsungData)[n], sep="")
}
for (n in 396:409) {
  colnames(samsungData)[n] <- paste("Y-", colnames(samsungData)[n], sep="")
}
for (n in 410:423) {
  colnames(samsungData)[n] <- paste("Z-", colnames(samsungData)[n], sep="")
}
for (n in 461:474) {
  colnames(samsungData)[n] <- paste("X-", colnames(samsungData)[n], sep="")
}
for (n in 475:488) {
  colnames(samsungData)[n] <- paste("Y-", colnames(samsungData)[n], sep="")
}
for (n in 489:502) {
  colnames(samsungData)[n] <- paste("Z-", colnames(samsungData)[n], sep="")
}

# short-cut to sanitized column names: (coerce out `-` and `(` and `)`)
samsungData <- data.frame(samsungData)
```

### Split the Data

> your training set must include the data from subjects 1, 3, 5, and 6 [...]
> Your test set is the data from subjects 27, 28, 29, and 30, but you may use
> more data to test. Be careful that your training/test sets do not overlap.

```{r}
set.seed(20130228)

trainConstants = c(1, 3, 5, 6)
testConstants = c(27, 28, 29, 30)
remainderSubjects = setdiff(setdiff(unique(samsungData$subject), trainConstants), testConstants)
trainConstants <- c(trainConstants, setdiff(remainderSubjects,
                                            sample(remainderSubjects, length(remainderSubjects)/2)))
testConstants <- c(testConstants, setdiff(remainderSubjects, trainConstants))


trainData = samsungData[samsungData$subject %in% trainConstants,]
testData = samsungData[samsungData$subject %in% testConstants,]
```

**SO:** _How do we build a predictive model for this???_
- 6 levels for 'activity' factor
- 561 data points
- how do we build a model for something like this?
- where do we start?

### REMINDER: What are the steps in building a predictive model?
1. ~~Find the right data~~  
   _A given in our case._
2. ~~Define your error rate~~  
   _Unsure how to proceed but... guess! pick one! Initial tree "with everything" came out to 0.101 error rate -- so approx. 10% -- so: 10% is the % to beat._
3. ~~Split data into:~~  
   _more/less defined for us_
4. ~~On the training set pick features~~  
   _Do the tree "with everything" and then see if it gives us any overlap w/ the max contributors from SVD; if there are, then take those and re-build the model; if there are not then just use the "winners" from the tree._
5. ~~On the training set pick prediction function~~  
   _...is this just the LM's model?_
6. On the training set cross-validate
7. If no validation - apply 1x to test set
8. If validation - apply to test set and refine
9. If validation - apply 1x to validation

### Try some `tree` shit...?
- so: the big problem is that the `tree` is a model like any other
- meaning: we need to do some cluster analysis (and/or _something_ else) to find
  the patterns -- what are the factors we're going to use in the tree's model?
- begging the question: did he spell a lot of this out for us? in week 4?

#### More data prep is in order?
```{r}
### Singular value decomposition?
train.svd <- trainData[,-c(562:564)]
for (c in names(train.svd)) {
  train.svd <- train.svd[!is.na(train.svd[[c]]),]
}

svd1 = svd(scale(train.svd))

#pca.of.train <- princomp(train.svd)
#pca.of.train$loadings

par(mfrow=c(1,2))
plot(svd1$d, xlab="Column", ylab="Singular value", pch=19)
svd1Pct <- svd1$d^2/sum(svd1$d^2)
plot(svd1Pct, xlab="Column", ylab="Percent of variance explained", pch=19)

par(mfrow=c(1,1))
plot(svd1$v[,2],pch=19)

# 5 values >= 200
svd1$d[svd1$d >= 200]
# 2 values >= 5%
svd1Pct[svd1Pct >= 0.05]

# get me the 5 max contributors
maxContrib <- which.max(svd1$v[,2])

second <- svd1$v[,2]
second <- second[! second %in% c(second[maxContrib])]
maxContrib2 <- which.max(second)

third <- second[! second %in% c(second[maxContrib2])]
maxContrib3 <- which.max(third)

fourth <- third[! third %in% c(third[maxContrib3])]
maxContrib4 <- which.max(fourth)

fifth <- fourth[! fourth %in% c(fourth[maxContrib4])]
maxContrib5 <- which.max(fifth)

maxContribs <- c(maxContrib, maxContrib2, maxContrib3, maxContrib4, maxContrib5)
names(train.svd)[maxContribs]
maxContribs.names <- sapply(maxContribs, function(x) names(trainData)[x])

### AN ALTERNATIVE APPROACH:
all.maxContribs <- apply(svd1$v, 2, which.max)
#length(all.maxContribs) # 561
#length(unique(all.maxContribs)) # 365
all.maxContribs.df <- as.data.frame(table(all.maxContribs))
all.maxContribs.df[all.maxContribs.df$Freq > 3,]
# 7 columns:
maxContribs2 <- as.numeric(as.vector(
  all.maxContribs.df[all.maxContribs.df$Freq > 3,]$all.maxContribs))
maxContribs2.names <- sapply(maxContribs2, function(x) names(trainData)[x])

### NO INTERSECTION
#intersect(maxContribs2.names, maxContribs.names)
# maxContribs2.names %in% maxContribs.names
#intersect(maxContribs.names, maxContribs2.names)
# maxContribs.names %in% maxContribs2.names
```

### Let's try a tree?
```{r}
library(tree)
#par(mfrow=c(2,1))
par(mfrow=c(1,1))
#trainTree <- tree(as.factor(trainData[["activity"]]) ~
#                  #trainData[[maxContribs.names[1]]] +
#                  #trainData[["fBodyAcc-meanFreq()-Z"]] +
#                  trainData[[296]] +
#                  #trainData[[maxContribs.names[2]]] +
#                  #trainData[["tGravityAcc-arCoeff()-Z,3"]] +
#                  trainData[[76]] +
#                  #trainData[[maxContribs.names[3]]] +
#                  #trainData[["tGravityAcc-arCoeff()-Z,1"]] +
#                  trainData[[74]] +
#                  #trainData[[maxContribs.names[4]]] +
#                  #trainData[["tGravityAccMag-iqr()"]] +
#                  trainData[[221]] +
#                  #trainData[[maxContribs.names[5]]],
#                  #trainData[["tBodyAccMag-iqr()"]],
#                  trainData[[208]],
#                  data=trainData)
trainTree <- tree(activity ~ ., data=trainData)

plot(trainTree)
text(trainTree)
summary(trainTree)

## compare SVD results vs. tree variables
# --- no intersection ---
tree.actualVariables <- c("fBodyAccJerk.std...X", "tGravityAcc.min...X",
                          "tGravityAcc.max...Y", "tBodyAccMag.std..",
                          "tGravityAcc.arCoeff...Y.2", "fBodyAccJerk.maxInds.X",
                          "tBodyGyro.arCoeff...Y.1" )
#intersect(tree.actualVariables, maxContribs.names) # NONE
intersect(tree.actualVariables, maxContribs2.names)
# "fBodyAccJerk.maxInds.X"

trainTree2 <- tree(activity ~ fBodyAccJerk.maxInds.X +
                     fBodyAccJerk.std...X + 
                     tGravityAcc.min...X +
                     tGravityAcc.max...Y +
                     tBodyAccMag.std.. +
                     tGravityAcc.arCoeff...Y.2 +
                     tBodyGyro.arCoeff...Y.1,
                   data=trainData)
plot(trainTree2)
text(trainTree2)
summary(trainTree2)

par(mfrow=c(1,1))
plot(trainTree)
text(trainTree)
summary(trainTree)

### a linear model, I guess...
lm1 <- lm(as.numeric(activity) ~ fBodyAccJerk.maxInds.X +
            fBodyAccJerk.std...X +
            tGravityAcc.min...X +
            tGravityAcc.max...Y +
            tBodyAccMag.std.. +
            tGravityAcc.arCoeff...Y.2 +
            tBodyGyro.arCoeff...Y.1,
          data=trainData)
summary(lm1)
confint(lm1)
anova(lm1)

### adapted from week 6 quiz
missClass = function(values, predictions) {
  abs(sum(values - round(predictions))) / length(values)
}

missClass(as.numeric(trainData$activity), predict(lm1, type="response"))
# 0.03789474 ... so about 3-4% (beats 10%)


# do it on the test data: drop the tail of prediction
missClass(as.numeric(testData$activity),
          predict(lm1, newData=testData, type="response")[1:length(testData$activity)])
# 0.05320946 -- about 5% (we'll take it)
```